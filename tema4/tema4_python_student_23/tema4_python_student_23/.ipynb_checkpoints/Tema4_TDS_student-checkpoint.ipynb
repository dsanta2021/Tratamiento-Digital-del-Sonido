{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 4 TDS Naturaleza y Percepción de la Señal Acústica\n",
    "\n",
    "#### Rebeca Goya Esteban y Óscar Barquero Pérez\n",
    "\n",
    "update: 17 de noviembre de 2019\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Licencia de Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />Este obra está bajo una <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">licencia de Creative Commons Reconocimiento-NoComercial-CompartirIgual 4.0 Internacional</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1. \n",
    "Genere una onda sinusoidal de duración 1 seg con amplitud 1 y frecuencia de muestreo $1 KHz$. Varíe la frecuencia del tono $f_0 = [100,200,300] Hz$. Represente y reproduzca los sonidos de diferentes frecuencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "#Example sinusoidal\n",
    "\n",
    "A =    # Amplitude\n",
    "f =  # Hz, fundamental frequency or pitch \n",
    "fs = # Hz, sampling frequency\n",
    "\n",
    "t = np.arange(0,1,1/fs)\n",
    "s = A*np.sin(2*np.pi*f*t)\n",
    "\n",
    "plt.figure(figsize = (6,4))\n",
    "\n",
    "plt.plot(t,s)\n",
    "\n",
    "#Audio(s,rate = fs)\n",
    "\n",
    "#try to sound using \n",
    "import sounddevice as sd\n",
    "\n",
    "sd.play(s,fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ejercicio 2. \n",
    "Represente la onda sinusoidal del ejercicio 1 para $f0 = [5, 10] Hz$, compruebe gráicamente el valor de los $T_0$. Represente también el móulo de la $\\mathcal{FFT}$ y compruebe el valor de $f_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import sys\n",
    "sys.path.append('../') #allows to import a module in a diff folder\n",
    "from tds_utils import my_spectra\n",
    "\n",
    "A=         #amplitude\n",
    "f1=        #Hz, fundamental frequency or pitch signal 1, \n",
    "f2=        # Hz, fundamental frequency or pitch frequency signal 2, \n",
    "fs=        # Hz, sampling frequency\n",
    "\n",
    "#generate temporal axes\n",
    "t = \n",
    "\n",
    "#generate signalsa\n",
    "s1= \n",
    "s2= \n",
    "\n",
    "#Plotting\n",
    "plt.figure(figsize =(7,5))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(t,s1)\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Amplitude')          \n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(t,s2)\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "#power spectral density estimation\n",
    "psd1,f = my_spectra(s1,fs)\n",
    "psd2,f = my_spectra(s2,fs)\n",
    "\n",
    "#plot positive frequencies\n",
    "\n",
    "plt.figure(figsize =(7,5))\n",
    "\n",
    "idx = f>=0\n",
    "plt.plot(f[idx],psd1[idx])\n",
    "plt.plot(f[idx],psd2[idx])\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('|FFT|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Observe las diferencias en el dominio del tiempo y en el dominio espectral entre señales de musicales y señales de voz.\n",
    "\n",
    "\n",
    "-Fíjese en las **frecuencias de muestreo (fs)** de cada una de las señales:\n",
    "    * ¿cuáles son? \n",
    "    * Relación con el periodo temporalen segundos del segmento de la señal que estamos representado.\n",
    "    * ¿cómo afectan a la representación espectral?\n",
    "    \n",
    "-Fíjese en que una señal de audio puede tener más de un **canal**.\n",
    "\n",
    "    *¿cómo extraemos uno de los canales para trabajar con él?\n",
    "    \n",
    "-¿Cuáles corresponde a una **señal de voz** y cuáles a una **señal musical**?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wf\n",
    "\n",
    "#reading wave files\n",
    "filename1 ='ejemploEj3_1_T4.wav'\n",
    "filename2 = 'ejemploEj3_2_T4.wav'\n",
    "filename3 = 'ejemploEj3_3_T4.wav'\n",
    "\n",
    "\n",
    "fs1,y1 = wf.read(filename1)\n",
    "trama1= y1[0:4000]\n",
    "t1 = np.arange(0,len(trama1)/fs1,1/fs1)\n",
    "\n",
    "fs2,y2 = wf.read(filename2)\n",
    "trama2= y2[0:7500,0]\n",
    "t2 = np.arange(0,len(trama2)/fs2,1/fs2)\n",
    "\n",
    "fs3,y3 = wf.read(filename3)\n",
    "trama3= y3[2500:4600]\n",
    "t3 = np.arange(0,(len(trama3))/fs3,1/fs3)\n",
    "\n",
    "\n",
    "#plot signals\n",
    "plt.figure(figsize = (7,5))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(t1,trama1)\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Amplitude')         \n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(t2,trama2)\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(t3,trama3)\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "psd1,f1 = my_spectra(trama1,fs1)\n",
    "psd2,f2 = my_spectra(trama2,fs2)\n",
    "psd3,f3 = my_spectra(trama3,fs3)\n",
    "\n",
    "#plot positive frequencies\n",
    "\n",
    "plt.figure(figsize =(7,5))\n",
    "\n",
    "idx1 = f1>=0\n",
    "idx2 = f2>=0\n",
    "idx3 = f3>=0\n",
    "\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(f1[idx1],psd1[idx1])\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('|FFT|')\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(f2[idx2],psd2[idx2])\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('|FFT|')\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(f3[idx3],psd3[idx3])\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('|FFT|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Represente el módulo de la FFT de la señal *ejemploEj4T4.npy*, identifique $f_0$ y y las frecuencias formantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#Loading ejemploEj3T4.npy\n",
    "ex = np.load('ejemploEj4T4.npy')\n",
    "\n",
    "#get dictionary from a numpy object\n",
    "ex = ex.item()\n",
    "\n",
    "#get sampling frequency and trama\n",
    "fs = ex['fs']\n",
    "\n",
    "trama = ex['trama']\n",
    "\n",
    "\n",
    "#plot signal\n",
    "plt.figure(figsize = (7,5))\n",
    "\n",
    "t = np.arange(0,len(trama)/fs,1/fs)\n",
    "\n",
    "\n",
    "#power spectral density estimation \n",
    "\n",
    "psd,f = \n",
    "\n",
    "#plot spectra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "Represente en el dominio temporal y en el dominio espectral los fragmentos de una señal de voz contenidos *ejemploEj5AT4.npy* y *ejemploEj5BT4.npy*, tome $fs = 11000\\ Hz$. Identifique qué fragmento es sonoro y qué fragmento es sordo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "#Load examples\n",
    "trama1 = np.load('ejemploEj5AT4.npy')\n",
    "trama2 = np.load('ejemploEj5BT4.npy')\n",
    "fs = 11e3\n",
    "\n",
    "#time vectors\n",
    "t1 = \n",
    "t2 = \n",
    "\n",
    "\n",
    "#Plot segments\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.subplot(211)\n",
    "plt.plot(t1,trama1)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(t2,trama2)\n",
    "\n",
    "#power spectral density estimation \n",
    "psd1,f1 = \n",
    "psd2,f2 = \n",
    "\n",
    "#plot spectra\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.subplot(211)\n",
    "idx1 = f1>= 0\n",
    "plt.plot(f1[idx1],psd1[idx1])\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('|FFT|')\n",
    "\n",
    "plt.subplot(212)\n",
    "idx2 = f2>= 0\n",
    "plt.plot(f2[idx2],psd2[idx2])\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('|FFT|')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

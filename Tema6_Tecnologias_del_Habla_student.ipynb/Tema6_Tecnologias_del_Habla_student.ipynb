{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 6 Tecnologías del Habla\n",
    "\n",
    "\n",
    "### Rebeca Goya Esteban y Óscar Barquero Pérez\n",
    "\n",
    "update: 15 de noviembre de 2022\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Licencia de Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />Este obra está bajo una <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">licencia de Creative Commons Reconocimiento-NoComercial-CompartirIgual 4.0 Internacional</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Clasificadores Máquina\n",
    "\n",
    "En este notebook vamos a aplicar tres técnicas de aprendizaje máquina para resolver un problema de clasificación.\n",
    "\n",
    "**Descripción de los datos**: The iris data sets consists of 3 different types of irises’ (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray\n",
    "The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "\n",
    "\n",
    "En la siguiente celda se cargan los datos y se realiza una división de los mismos en un conjunto de entrenamiento y un conjunto de test. En *X_train* y *X_test* corresponden a carcterı́sticas de tres clases de flores, en total hay 150\n",
    "ejemplos. En *y_train* y *y_test* se encuentra la información de a qué clase\n",
    "pertenece cada una de las 150 flores (tres posibles clases).\n",
    "\n",
    "**¿Cuántas características se están utilizando para representar/describir a cada una de las flores?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#imports\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "#load datasets and split into test and train\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  \n",
    "y = iris.target\n",
    "\n",
    "#30% de test\n",
    "\n",
    "#split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Naive Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar el Método de Clasificación de [Naïve Bayes GaussianNB](http://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes), donde hay dos asunciones básicas:\n",
    "\n",
    "* Asunción *naïve* de independencia condicional entre las características para una clase de la variable respuesta dada:\n",
    "\n",
    "$$P(x_1,\\ldots,x_d\\mid y_i) = \\prod_{k = 1}^{d}P(x_k\\mid y_i)$$\n",
    "\n",
    "* La verosimilitud de cada una de las características se asume Gaussiana:\n",
    "\n",
    "$$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "A continuación entrenamos el algoritmo, lo que implica calcular los parámetros $\\mu_y$ y $\\sigma_y$.\n",
    "\n",
    "* Utilice los datos de entrenamiento (*X_Train* y *y_Train*) y la función *GaussianNB.fit()* para estimar los parámetros de la pdf gaussiana de cada una de las 3 clases de flores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.3 3.7 1.5 0.2]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Creamos el modelo de NB\n",
    "\n",
    "model_NB = GaussianNB()\n",
    "\n",
    "#entrenamos\n",
    "\n",
    "model_NB.fit(X_train, y_train)\n",
    "\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de la gaussiana para cada clase:\n",
      " Columnas = Características \n",
      " Filas = Clases\n",
      "\n",
      "[[5.03225806 3.40967742 1.47096774 0.26129032]\n",
      " [5.92222222 2.76944444 4.24166667 1.32777778]\n",
      " [6.58684211 2.99473684 5.56842105 2.04210526]]\n"
     ]
    }
   ],
   "source": [
    "# Media y desviación estándar para las características de cada clase:\n",
    "\n",
    "print(\"Media de la gaussiana para cada clase:\\n Columnas = Características \\n Filas = Clases\\n\")\n",
    "print(model_NB.theta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desviación estándar de la gaussiana para cada clase:\n",
      " Columnas = Características \n",
      " Filas = Clases\n",
      "\n",
      "[[0.12734652 0.10861603 0.02915713 0.01334027]\n",
      " [0.30228395 0.11934414 0.22909723 0.03811729]\n",
      " [0.39377424 0.10891967 0.29952909 0.06296399]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Desviación estándar de la gaussiana para cada clase:\\n Columnas = Características \\n Filas = Clases\\n\")\n",
    "print(model_NB.sigma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "* Clasifique cada ejemplo (flor) de los datos de test (x test iris y y test iris) de acuerdo al esquema de clasificación Naive Bayes. Para ello, utilice *model_NB.predict(X_test)*\n",
    "* Calcule el error de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n",
      "[2 2 0 1 2 0 1 0 2 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 2 0 0 2 0 2 2 1 2 1 0 1 0\n",
      " 1 1 0 0 0 2 0 0]\n",
      "[2 2 0 2 2 0 1 0 2 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 2 0 0 2 0 2 2 1 2 1 0 1 0\n",
      " 1 2 0 0 0 2 0 0]\n",
      "[[6.9 3.1 5.4 2.1]\n",
      " [6.  3.  4.8 1.8]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [5.4 3.9 1.7 0.4]]\n"
     ]
    }
   ],
   "source": [
    "# Predecimos las muestras de test, utilizando los valores de la función estimados anteriorment en train\n",
    "\n",
    "y_hat_NB = model_NB.predict(X_test)\n",
    "\n",
    "#Calculamos el accuracy (exactitud = mº de actiertos/nº de casos totales)\n",
    "\n",
    "acc_NB = np.mean(y_test == y_hat_NB)\n",
    "print(acc_NB)\n",
    "print(y_hat_NB)\n",
    "print(y_test)\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 Ejemplo KNN con sklearn\n",
    "\n",
    "Vamos a utilizar el método de clasificación KNN https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "**Pruebe diferentes valores para el parámetro K**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n",
      "[[5.3 3.7 1.5 0.2]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#train the model \n",
    "\n",
    "model_KNN.fit(X_train, y_train)\n",
    "\n",
    "#predict outputs\n",
    "\n",
    "y_hat_KNN = model_KNN.predict(X_test)\n",
    "\n",
    "#accuracy\n",
    "\n",
    "acc = np.mean(y_test == y_hat_KNN)\n",
    "\n",
    "print(acc)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.3 redes neuronales\n",
    "\n",
    "Vamos a utilizar el método de clasificación redes neuronales https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "\n",
    "**Pruebe diferentes configuraciones de capas y neuronas ocultas**\n",
    "\n",
    "**Pruebe o modificar otros parámetros de la red neuronal**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_RN = MLPClassifier(hidden_layer_sizes=(1,10)) #nº capas, nº neuronas\n",
    "\n",
    "#train the model \n",
    "\n",
    "model_RN.fit(X_train, y_train)\n",
    "\n",
    "#predict outputs\n",
    "y_hat_RN = model_RN.predict(X_test)\n",
    "\n",
    "#accuracy\n",
    "\n",
    "acc = np.mean(y_test == y_hat_RN)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
